{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Web Application for an ETF Analyzer\n",
    "\n",
    "In this Challenge assignment, you’ll build a financial database and web application by using SQL, Python, and the Voilà library to analyze the performance of a hypothetical fintech ETF.\n",
    "\n",
    "Instructions: \n",
    "\n",
    "Use this notebook to complete your analysis of a fintech ETF that consists of four stocks: GOST, GS, PYPL, and SQ. Each stock has its own table in the `etf.db` database, which the `Starter_Code` folder also contains.\n",
    "\n",
    "Analyze the daily returns of the ETF stocks both individually and as a whole. Then deploy the visualizations to a web application by using the Voilà library.\n",
    "\n",
    "The detailed instructions are divided into the following parts:\n",
    "\n",
    "* Analyze a single asset in the ETF\n",
    "\n",
    "* Optimize data access with Advanced SQL queries\n",
    "\n",
    "* Analyze the ETF portfolio\n",
    "\n",
    "* Deploy the notebook as a web application\n",
    "\n",
    "#### Analyze a Single Asset in the ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Optimize Data Access with Advanced SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "#### Analyze the ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Deploy the Notebook as a Web Application\n",
    "\n",
    "For this part of the assignment, complete the following steps:\n",
    "\n",
    "1. Use the Voilà library to deploy your notebook as a web application. You can deploy the web application locally on your computer.\n",
    "\n",
    "2. Take a screen recording or screenshots to show how the web application appears when using Voilà. Include the recording or screenshots in the `README.md` file for your GitHub repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the following code which imports the required libraries, initiates your SQLite database, popluates the database with records from the `etf.db` seed file that was included in your Starter_Code folder, creates the database engine, and confirms that data tables that it now contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferjackson/opt/anaconda3/envs/dev/lib/python3.7/site-packages/ipykernel_launcher.py:14: SADeprecationWarning: The Engine.table_names() method is deprecated and will be removed in a future release.  Please refer to Inspector.get_table_names(). (deprecated since: 1.4)\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import sqlalchemy\n",
    "\n",
    "# Create a temporary SQLite database and populate the database with content from the etf.db seed file\n",
    "database_string = 'sqlite:///etf.db'\n",
    "\n",
    "# Create an engine to interact with the SQLite database\n",
    "engine = sqlalchemy.create_engine(database_string)\n",
    "\n",
    "# Confirm that table names contained in the SQLite database.\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a single asset in the FinTech ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: PYPL\n[SQL: \nSELECT *FROM PYPL\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1772\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1773\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: PYPL",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_49441/1640658308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcolumn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daily_returns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpypl_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_all_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0m_warn_with_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \"\"\"\n\u001b[1;32m   3107\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m     @util.deprecated_20(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0m_EMPTY_EXECUTION_OPTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mfuture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             )\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0mexecution_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mdistilled_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         )\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1815\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m             )\n\u001b[1;32m   1817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1994\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m                 util.raise_(\n\u001b[0;32m-> 1996\u001b[0;31m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m                 )\n\u001b[1;32m   1998\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1772\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1773\u001b[0m                     )\n\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: PYPL\n[SQL: \nSELECT *FROM PYPL\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# Write a SQL query to SELECT all of the data from the PYPL table\n",
    "read_all_data= \"\"\"\n",
    "SELECT *FROM PYPL\n",
    "\"\"\"\n",
    "\n",
    "# Use the query to read the PYPL data into a Pandas DataFrame\n",
    "\n",
    "column_list = ['time', 'open', 'high', 'low', 'close', 'volume', 'daily_returns']\n",
    "pypl_dataframe = pd.DataFrame(engine.execute(read_all_data), columns=column_list)\n",
    "pypl_dataframe['time'] = pd.to_datetime(pypl_dataframe['time'])\n",
    "\n",
    "pypl_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pypl_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_49441/3256444930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# View the first 5 rows of the DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pypl_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# View the first 5 rows of the DataFrame.\n",
    "pypl_dataframe.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pypl_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_49441/1513307861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# View the last 5 rows of the DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pypl_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# View the last 5 rows of the DataFrame.\n",
    "pypl_dataframe.tail(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pypl_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_49441/418516736.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Use hvplot() function to plot your DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Label the x-axis \"Date\" and the y-axis \"Return\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Daily Returns %\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daily_returns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m pypl_dataframe.hvplot(\n\u001b[1;32m      6\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PYPL Daily Returns (%)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pypl_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an interactive visualization with hvplot to plot the daily returns for PYPL.\n",
    "# Use hvplot() function to plot your DataFrame\n",
    "# Label the x-axis \"Date\" and the y-axis \"Return\"\n",
    "pypl_dataframe[\"Daily Returns %\"] = pypl_dataframe['daily_returns']*100\n",
    "pypl_dataframe.hvplot(\n",
    "    title=\"PYPL Daily Returns (%)\"\n",
    "    ,y='daily_returns'\n",
    "    ,xlabel= 'Date'\n",
    "    ,ylabel='Returns (%)'\n",
    "    ,width=800\n",
    ").opts(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pypl_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_49441/1975887317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrowth_of_1usd_investment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpypl_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_returns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Transforming a series to a dataframe and renaming columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrowth_of_1usd_investment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrowth_of_1usd_investment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'daily_returns'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Growth of 1 USD Investment'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pypl_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\n",
    "growth_of_1usd_investment=(1+pypl_dataframe[\"daily_returns\"]).cumprod()\n",
    "\n",
    "#Transforming a series to a dataframe and renaming columns\n",
    "growth_of_1usd_investment = growth_of_1usd_investment.to_frame().rename(columns={'daily_returns':'Growth of 1 USD Investment'})\n",
    "print(\"\\033[1m Table: Evolution of a $1 initial investment on Dec 16th 2016 on the ETF.\")\n",
    "\n",
    "display(growth_of_1usd_investment)\n",
    "\n",
    "# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\n",
    "growth_of_1usd_investment.hvplot(\n",
    "    title=\"Paypal Holdings Inc -- Growth of 1 USD Initial Investment -- Period Dec-16-2016 to Dec 4th 2020\"\n",
    "    ,ylabel=\"Initial Investment \\n plus Cumulative Return\"\n",
    "    ,xlabel= \"Date\"\n",
    "    ,width=900)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-05 00:00:00.000000</td>\n",
       "      <td>199.0000</td>\n",
       "      <td>204.2300</td>\n",
       "      <td>198.0900</td>\n",
       "      <td>202.920</td>\n",
       "      <td>6231740</td>\n",
       "      <td>0.027911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06 00:00:00.000000</td>\n",
       "      <td>202.0000</td>\n",
       "      <td>204.1600</td>\n",
       "      <td>198.8800</td>\n",
       "      <td>204.090</td>\n",
       "      <td>5131981</td>\n",
       "      <td>0.005766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-25 00:00:00.000000</td>\n",
       "      <td>198.4900</td>\n",
       "      <td>201.9600</td>\n",
       "      <td>196.2400</td>\n",
       "      <td>201.710</td>\n",
       "      <td>3911979</td>\n",
       "      <td>0.013924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-26 00:00:00.000000</td>\n",
       "      <td>202.5300</td>\n",
       "      <td>205.3500</td>\n",
       "      <td>200.2500</td>\n",
       "      <td>203.530</td>\n",
       "      <td>4572164</td>\n",
       "      <td>0.009023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-27 00:00:00.000000</td>\n",
       "      <td>206.8100</td>\n",
       "      <td>207.0000</td>\n",
       "      <td>202.3000</td>\n",
       "      <td>204.340</td>\n",
       "      <td>5161700</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-08-28 00:00:00.000000</td>\n",
       "      <td>205.4159</td>\n",
       "      <td>205.4159</td>\n",
       "      <td>202.4200</td>\n",
       "      <td>204.480</td>\n",
       "      <td>3723872</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-08-31 00:00:00.000000</td>\n",
       "      <td>203.7000</td>\n",
       "      <td>205.2523</td>\n",
       "      <td>202.2984</td>\n",
       "      <td>203.950</td>\n",
       "      <td>4541288</td>\n",
       "      <td>-0.002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-09-01 00:00:00.000000</td>\n",
       "      <td>205.5900</td>\n",
       "      <td>209.8799</td>\n",
       "      <td>205.1450</td>\n",
       "      <td>208.920</td>\n",
       "      <td>5344347</td>\n",
       "      <td>0.024369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-02 00:00:00.000000</td>\n",
       "      <td>211.6222</td>\n",
       "      <td>212.4500</td>\n",
       "      <td>204.6000</td>\n",
       "      <td>210.820</td>\n",
       "      <td>6467777</td>\n",
       "      <td>0.009094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-09-03 00:00:00.000000</td>\n",
       "      <td>205.6900</td>\n",
       "      <td>206.5900</td>\n",
       "      <td>194.9500</td>\n",
       "      <td>205.070</td>\n",
       "      <td>14251722</td>\n",
       "      <td>-0.027274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-10-12 00:00:00.000000</td>\n",
       "      <td>199.8700</td>\n",
       "      <td>204.0800</td>\n",
       "      <td>196.6323</td>\n",
       "      <td>201.500</td>\n",
       "      <td>8963835</td>\n",
       "      <td>0.021443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-10-13 00:00:00.000000</td>\n",
       "      <td>202.1500</td>\n",
       "      <td>208.9500</td>\n",
       "      <td>200.1100</td>\n",
       "      <td>207.730</td>\n",
       "      <td>6429243</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-10-14 00:00:00.000000</td>\n",
       "      <td>208.2035</td>\n",
       "      <td>208.9480</td>\n",
       "      <td>200.5000</td>\n",
       "      <td>203.660</td>\n",
       "      <td>7622162</td>\n",
       "      <td>-0.019593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-15 00:00:00.000000</td>\n",
       "      <td>199.9900</td>\n",
       "      <td>203.4800</td>\n",
       "      <td>198.1280</td>\n",
       "      <td>203.170</td>\n",
       "      <td>6217366</td>\n",
       "      <td>-0.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-10-16 00:00:00.000000</td>\n",
       "      <td>204.4400</td>\n",
       "      <td>207.4700</td>\n",
       "      <td>202.2200</td>\n",
       "      <td>204.540</td>\n",
       "      <td>8786056</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-10-19 00:00:00.000000</td>\n",
       "      <td>205.6400</td>\n",
       "      <td>207.2300</td>\n",
       "      <td>199.1000</td>\n",
       "      <td>200.050</td>\n",
       "      <td>5098521</td>\n",
       "      <td>-0.021952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-10-20 00:00:00.000000</td>\n",
       "      <td>201.1400</td>\n",
       "      <td>205.4700</td>\n",
       "      <td>200.3100</td>\n",
       "      <td>201.960</td>\n",
       "      <td>4080299</td>\n",
       "      <td>0.009548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-10-21 00:00:00.000000</td>\n",
       "      <td>208.3000</td>\n",
       "      <td>215.8300</td>\n",
       "      <td>206.0200</td>\n",
       "      <td>213.060</td>\n",
       "      <td>13396160</td>\n",
       "      <td>0.054961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-10-22 00:00:00.000000</td>\n",
       "      <td>211.9000</td>\n",
       "      <td>212.3400</td>\n",
       "      <td>202.1403</td>\n",
       "      <td>203.880</td>\n",
       "      <td>10988041</td>\n",
       "      <td>-0.043086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-10-23 00:00:00.000000</td>\n",
       "      <td>206.2400</td>\n",
       "      <td>206.2400</td>\n",
       "      <td>201.2100</td>\n",
       "      <td>203.040</td>\n",
       "      <td>5836734</td>\n",
       "      <td>-0.004120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-10-27 00:00:00.000000</td>\n",
       "      <td>198.7900</td>\n",
       "      <td>201.3200</td>\n",
       "      <td>197.7200</td>\n",
       "      <td>200.440</td>\n",
       "      <td>3462757</td>\n",
       "      <td>0.016378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-11-05 00:00:00.000000</td>\n",
       "      <td>202.3000</td>\n",
       "      <td>204.9200</td>\n",
       "      <td>199.3700</td>\n",
       "      <td>204.590</td>\n",
       "      <td>12618928</td>\n",
       "      <td>0.053447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-11-06 00:00:00.000000</td>\n",
       "      <td>204.6000</td>\n",
       "      <td>204.9200</td>\n",
       "      <td>198.5500</td>\n",
       "      <td>202.720</td>\n",
       "      <td>7075679</td>\n",
       "      <td>-0.009140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-11-23 00:00:00.000000</td>\n",
       "      <td>194.5300</td>\n",
       "      <td>202.1600</td>\n",
       "      <td>193.9200</td>\n",
       "      <td>200.820</td>\n",
       "      <td>10519696</td>\n",
       "      <td>0.042571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-11-24 00:00:00.000000</td>\n",
       "      <td>204.0000</td>\n",
       "      <td>207.0791</td>\n",
       "      <td>198.8600</td>\n",
       "      <td>206.000</td>\n",
       "      <td>13072036</td>\n",
       "      <td>0.025794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-11-25 00:00:00.000000</td>\n",
       "      <td>206.2900</td>\n",
       "      <td>216.0700</td>\n",
       "      <td>206.2300</td>\n",
       "      <td>214.380</td>\n",
       "      <td>11779276</td>\n",
       "      <td>0.040680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-11-27 00:00:00.000000</td>\n",
       "      <td>213.2000</td>\n",
       "      <td>213.8400</td>\n",
       "      <td>208.6200</td>\n",
       "      <td>211.320</td>\n",
       "      <td>4806373</td>\n",
       "      <td>-0.014274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-11-30 00:00:00.000000</td>\n",
       "      <td>212.5100</td>\n",
       "      <td>215.8300</td>\n",
       "      <td>207.0900</td>\n",
       "      <td>214.200</td>\n",
       "      <td>8992681</td>\n",
       "      <td>0.013629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-12-01 00:00:00.000000</td>\n",
       "      <td>217.1500</td>\n",
       "      <td>220.5700</td>\n",
       "      <td>214.3401</td>\n",
       "      <td>216.520</td>\n",
       "      <td>9148174</td>\n",
       "      <td>0.010831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-12-02 00:00:00.000000</td>\n",
       "      <td>215.6000</td>\n",
       "      <td>215.7500</td>\n",
       "      <td>210.5000</td>\n",
       "      <td>212.660</td>\n",
       "      <td>6414746</td>\n",
       "      <td>-0.017827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-12-03 00:00:00.000000</td>\n",
       "      <td>213.3300</td>\n",
       "      <td>216.9300</td>\n",
       "      <td>213.1100</td>\n",
       "      <td>214.680</td>\n",
       "      <td>6463339</td>\n",
       "      <td>0.009499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-12-04 00:00:00.000000</td>\n",
       "      <td>214.8800</td>\n",
       "      <td>217.2800</td>\n",
       "      <td>213.0100</td>\n",
       "      <td>217.235</td>\n",
       "      <td>2118319</td>\n",
       "      <td>0.011901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time      open      high       low    close  \\\n",
       "0   2020-08-05 00:00:00.000000  199.0000  204.2300  198.0900  202.920   \n",
       "1   2020-08-06 00:00:00.000000  202.0000  204.1600  198.8800  204.090   \n",
       "2   2020-08-25 00:00:00.000000  198.4900  201.9600  196.2400  201.710   \n",
       "3   2020-08-26 00:00:00.000000  202.5300  205.3500  200.2500  203.530   \n",
       "4   2020-08-27 00:00:00.000000  206.8100  207.0000  202.3000  204.340   \n",
       "5   2020-08-28 00:00:00.000000  205.4159  205.4159  202.4200  204.480   \n",
       "6   2020-08-31 00:00:00.000000  203.7000  205.2523  202.2984  203.950   \n",
       "7   2020-09-01 00:00:00.000000  205.5900  209.8799  205.1450  208.920   \n",
       "8   2020-09-02 00:00:00.000000  211.6222  212.4500  204.6000  210.820   \n",
       "9   2020-09-03 00:00:00.000000  205.6900  206.5900  194.9500  205.070   \n",
       "10  2020-10-12 00:00:00.000000  199.8700  204.0800  196.6323  201.500   \n",
       "11  2020-10-13 00:00:00.000000  202.1500  208.9500  200.1100  207.730   \n",
       "12  2020-10-14 00:00:00.000000  208.2035  208.9480  200.5000  203.660   \n",
       "13  2020-10-15 00:00:00.000000  199.9900  203.4800  198.1280  203.170   \n",
       "14  2020-10-16 00:00:00.000000  204.4400  207.4700  202.2200  204.540   \n",
       "15  2020-10-19 00:00:00.000000  205.6400  207.2300  199.1000  200.050   \n",
       "16  2020-10-20 00:00:00.000000  201.1400  205.4700  200.3100  201.960   \n",
       "17  2020-10-21 00:00:00.000000  208.3000  215.8300  206.0200  213.060   \n",
       "18  2020-10-22 00:00:00.000000  211.9000  212.3400  202.1403  203.880   \n",
       "19  2020-10-23 00:00:00.000000  206.2400  206.2400  201.2100  203.040   \n",
       "20  2020-10-27 00:00:00.000000  198.7900  201.3200  197.7200  200.440   \n",
       "21  2020-11-05 00:00:00.000000  202.3000  204.9200  199.3700  204.590   \n",
       "22  2020-11-06 00:00:00.000000  204.6000  204.9200  198.5500  202.720   \n",
       "23  2020-11-23 00:00:00.000000  194.5300  202.1600  193.9200  200.820   \n",
       "24  2020-11-24 00:00:00.000000  204.0000  207.0791  198.8600  206.000   \n",
       "25  2020-11-25 00:00:00.000000  206.2900  216.0700  206.2300  214.380   \n",
       "26  2020-11-27 00:00:00.000000  213.2000  213.8400  208.6200  211.320   \n",
       "27  2020-11-30 00:00:00.000000  212.5100  215.8300  207.0900  214.200   \n",
       "28  2020-12-01 00:00:00.000000  217.1500  220.5700  214.3401  216.520   \n",
       "29  2020-12-02 00:00:00.000000  215.6000  215.7500  210.5000  212.660   \n",
       "30  2020-12-03 00:00:00.000000  213.3300  216.9300  213.1100  214.680   \n",
       "31  2020-12-04 00:00:00.000000  214.8800  217.2800  213.0100  217.235   \n",
       "\n",
       "      volume  daily_returns  \n",
       "0    6231740       0.027911  \n",
       "1    5131981       0.005766  \n",
       "2    3911979       0.013924  \n",
       "3    4572164       0.009023  \n",
       "4    5161700       0.003980  \n",
       "5    3723872       0.000685  \n",
       "6    4541288      -0.002592  \n",
       "7    5344347       0.024369  \n",
       "8    6467777       0.009094  \n",
       "9   14251722      -0.027274  \n",
       "10   8963835       0.021443  \n",
       "11   6429243       0.030918  \n",
       "12   7622162      -0.019593  \n",
       "13   6217366      -0.002406  \n",
       "14   8786056       0.006743  \n",
       "15   5098521      -0.021952  \n",
       "16   4080299       0.009548  \n",
       "17  13396160       0.054961  \n",
       "18  10988041      -0.043086  \n",
       "19   5836734      -0.004120  \n",
       "20   3462757       0.016378  \n",
       "21  12618928       0.053447  \n",
       "22   7075679      -0.009140  \n",
       "23  10519696       0.042571  \n",
       "24  13072036       0.025794  \n",
       "25  11779276       0.040680  \n",
       "26   4806373      -0.014274  \n",
       "27   8992681       0.013629  \n",
       "28   9148174       0.010831  \n",
       "29   6414746      -0.017827  \n",
       "30   6463339       0.009499  \n",
       "31   2118319       0.011901  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a SQL SELECT statement to select the time and close columns \n",
    "# where the PYPL closing price was higher than 200.0.\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM PYPL\n",
    "WHERE close > 200\n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_higher_than_200_df = pd.read_sql(query, con = engine)\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "pypl_higher_than_200_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-04 00:00:00.000000</td>\n",
       "      <td>214.8800</td>\n",
       "      <td>217.2800</td>\n",
       "      <td>213.0100</td>\n",
       "      <td>217.235</td>\n",
       "      <td>2118319</td>\n",
       "      <td>0.011901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-01 00:00:00.000000</td>\n",
       "      <td>217.1500</td>\n",
       "      <td>220.5700</td>\n",
       "      <td>214.3401</td>\n",
       "      <td>216.520</td>\n",
       "      <td>9148174</td>\n",
       "      <td>0.010831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-03 00:00:00.000000</td>\n",
       "      <td>213.3300</td>\n",
       "      <td>216.9300</td>\n",
       "      <td>213.1100</td>\n",
       "      <td>214.680</td>\n",
       "      <td>6463339</td>\n",
       "      <td>0.009499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-25 00:00:00.000000</td>\n",
       "      <td>206.2900</td>\n",
       "      <td>216.0700</td>\n",
       "      <td>206.2300</td>\n",
       "      <td>214.380</td>\n",
       "      <td>11779276</td>\n",
       "      <td>0.040680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-30 00:00:00.000000</td>\n",
       "      <td>212.5100</td>\n",
       "      <td>215.8300</td>\n",
       "      <td>207.0900</td>\n",
       "      <td>214.200</td>\n",
       "      <td>8992681</td>\n",
       "      <td>0.013629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-21 00:00:00.000000</td>\n",
       "      <td>208.3000</td>\n",
       "      <td>215.8300</td>\n",
       "      <td>206.0200</td>\n",
       "      <td>213.060</td>\n",
       "      <td>13396160</td>\n",
       "      <td>0.054961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-12-02 00:00:00.000000</td>\n",
       "      <td>215.6000</td>\n",
       "      <td>215.7500</td>\n",
       "      <td>210.5000</td>\n",
       "      <td>212.660</td>\n",
       "      <td>6414746</td>\n",
       "      <td>-0.017827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-27 00:00:00.000000</td>\n",
       "      <td>213.2000</td>\n",
       "      <td>213.8400</td>\n",
       "      <td>208.6200</td>\n",
       "      <td>211.320</td>\n",
       "      <td>4806373</td>\n",
       "      <td>-0.014274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-02 00:00:00.000000</td>\n",
       "      <td>211.6222</td>\n",
       "      <td>212.4500</td>\n",
       "      <td>204.6000</td>\n",
       "      <td>210.820</td>\n",
       "      <td>6467777</td>\n",
       "      <td>0.009094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-09-01 00:00:00.000000</td>\n",
       "      <td>205.5900</td>\n",
       "      <td>209.8799</td>\n",
       "      <td>205.1450</td>\n",
       "      <td>208.920</td>\n",
       "      <td>5344347</td>\n",
       "      <td>0.024369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time      open      high       low    close  \\\n",
       "0  2020-12-04 00:00:00.000000  214.8800  217.2800  213.0100  217.235   \n",
       "1  2020-12-01 00:00:00.000000  217.1500  220.5700  214.3401  216.520   \n",
       "2  2020-12-03 00:00:00.000000  213.3300  216.9300  213.1100  214.680   \n",
       "3  2020-11-25 00:00:00.000000  206.2900  216.0700  206.2300  214.380   \n",
       "4  2020-11-30 00:00:00.000000  212.5100  215.8300  207.0900  214.200   \n",
       "5  2020-10-21 00:00:00.000000  208.3000  215.8300  206.0200  213.060   \n",
       "6  2020-12-02 00:00:00.000000  215.6000  215.7500  210.5000  212.660   \n",
       "7  2020-11-27 00:00:00.000000  213.2000  213.8400  208.6200  211.320   \n",
       "8  2020-09-02 00:00:00.000000  211.6222  212.4500  204.6000  210.820   \n",
       "9  2020-09-01 00:00:00.000000  205.5900  209.8799  205.1450  208.920   \n",
       "\n",
       "     volume  daily_returns  \n",
       "0   2118319       0.011901  \n",
       "1   9148174       0.010831  \n",
       "2   6463339       0.009499  \n",
       "3  11779276       0.040680  \n",
       "4   8992681       0.013629  \n",
       "5  13396160       0.054961  \n",
       "6   6414746      -0.017827  \n",
       "7   4806373      -0.014274  \n",
       "8   6467777       0.009094  \n",
       "9   5344347       0.024369  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a SQL SELECT statement to select the time and daily_returns columns\n",
    "# Sort the results in descending order and return only the top 10 return values\n",
    "query = \"\"\"\n",
    "SELECT* \n",
    "FROM PYPL\n",
    "WHERE close > 200\n",
    "ORDER BY close DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_top_10_returns = pd.read_sql(query, con = engine)\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "pypl_top_10_returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Fintech ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>...</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-16 00:00:00.000000</td>\n",
       "      <td>24.41</td>\n",
       "      <td>24.73</td>\n",
       "      <td>23.94</td>\n",
       "      <td>23.980</td>\n",
       "      <td>483544</td>\n",
       "      <td>-0.023218</td>\n",
       "      <td>2016-12-16 00:00:00.000000</td>\n",
       "      <td>242.80</td>\n",
       "      <td>243.19</td>\n",
       "      <td>...</td>\n",
       "      <td>39.32</td>\n",
       "      <td>7298861</td>\n",
       "      <td>-0.005564</td>\n",
       "      <td>2016-12-16 00:00:00.000000</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.47</td>\n",
       "      <td>14.2300</td>\n",
       "      <td>14.375</td>\n",
       "      <td>4516341</td>\n",
       "      <td>0.017339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-19 00:00:00.000000</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.01</td>\n",
       "      <td>23.55</td>\n",
       "      <td>23.790</td>\n",
       "      <td>288149</td>\n",
       "      <td>-0.007923</td>\n",
       "      <td>2016-12-19 00:00:00.000000</td>\n",
       "      <td>238.34</td>\n",
       "      <td>239.74</td>\n",
       "      <td>...</td>\n",
       "      <td>39.45</td>\n",
       "      <td>3436478</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>2016-12-19 00:00:00.000000</td>\n",
       "      <td>14.34</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>14.360</td>\n",
       "      <td>3944657</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-20 00:00:00.000000</td>\n",
       "      <td>23.75</td>\n",
       "      <td>23.94</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.820</td>\n",
       "      <td>220341</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>2016-12-20 00:00:00.000000</td>\n",
       "      <td>240.52</td>\n",
       "      <td>243.65</td>\n",
       "      <td>...</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2940991</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>2016-12-20 00:00:00.000000</td>\n",
       "      <td>14.73</td>\n",
       "      <td>14.82</td>\n",
       "      <td>14.4100</td>\n",
       "      <td>14.490</td>\n",
       "      <td>5207412</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-21 00:00:00.000000</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.97</td>\n",
       "      <td>23.69</td>\n",
       "      <td>23.860</td>\n",
       "      <td>249189</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>2016-12-21 00:00:00.000000</td>\n",
       "      <td>242.24</td>\n",
       "      <td>242.40</td>\n",
       "      <td>...</td>\n",
       "      <td>40.09</td>\n",
       "      <td>5826704</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>2016-12-21 00:00:00.000000</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.54</td>\n",
       "      <td>14.2701</td>\n",
       "      <td>14.380</td>\n",
       "      <td>3901738</td>\n",
       "      <td>-0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-22 00:00:00.000000</td>\n",
       "      <td>23.90</td>\n",
       "      <td>24.01</td>\n",
       "      <td>23.70</td>\n",
       "      <td>24.005</td>\n",
       "      <td>383139</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>2016-12-22 00:00:00.000000</td>\n",
       "      <td>241.23</td>\n",
       "      <td>242.86</td>\n",
       "      <td>...</td>\n",
       "      <td>39.68</td>\n",
       "      <td>4338385</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>2016-12-22 00:00:00.000000</td>\n",
       "      <td>14.33</td>\n",
       "      <td>14.34</td>\n",
       "      <td>13.9301</td>\n",
       "      <td>14.040</td>\n",
       "      <td>3874004</td>\n",
       "      <td>-0.023644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time   open   high    low   close  volume  \\\n",
       "0  2016-12-16 00:00:00.000000  24.41  24.73  23.94  23.980  483544   \n",
       "1  2016-12-19 00:00:00.000000  24.00  24.01  23.55  23.790  288149   \n",
       "2  2016-12-20 00:00:00.000000  23.75  23.94  23.58  23.820  220341   \n",
       "3  2016-12-21 00:00:00.000000  23.90  23.97  23.69  23.860  249189   \n",
       "4  2016-12-22 00:00:00.000000  23.90  24.01  23.70  24.005  383139   \n",
       "\n",
       "   daily_returns                        time    open    high  ...  close  \\\n",
       "0      -0.023218  2016-12-16 00:00:00.000000  242.80  243.19  ...  39.32   \n",
       "1      -0.007923  2016-12-19 00:00:00.000000  238.34  239.74  ...  39.45   \n",
       "2       0.001261  2016-12-20 00:00:00.000000  240.52  243.65  ...  39.74   \n",
       "3       0.001679  2016-12-21 00:00:00.000000  242.24  242.40  ...  40.09   \n",
       "4       0.006077  2016-12-22 00:00:00.000000  241.23  242.86  ...  39.68   \n",
       "\n",
       "    volume  daily_returns                        time   open   high      low  \\\n",
       "0  7298861      -0.005564  2016-12-16 00:00:00.000000  14.29  14.47  14.2300   \n",
       "1  3436478       0.003306  2016-12-19 00:00:00.000000  14.34  14.60  14.3000   \n",
       "2  2940991       0.007351  2016-12-20 00:00:00.000000  14.73  14.82  14.4100   \n",
       "3  5826704       0.008807  2016-12-21 00:00:00.000000  14.45  14.54  14.2701   \n",
       "4  4338385      -0.010227  2016-12-22 00:00:00.000000  14.33  14.34  13.9301   \n",
       "\n",
       "    close   volume  daily_returns  \n",
       "0  14.375  4516341       0.017339  \n",
       "1  14.360  3944657      -0.001043  \n",
       "2  14.490  5207412       0.009053  \n",
       "3  14.380  3901738      -0.007591  \n",
       "4  14.040  3874004      -0.023644  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wreate a SQL query to join each table in the portfolio into a single DataFrame \n",
    "# Use the time column from each table as the basis for the join\n",
    "query = \"\"\"\n",
    "SELECT* \n",
    "FROM GDOT, GS, PYPL, SQ\n",
    "WHERE GDOT.time = GS.time\n",
    "AND PYPL.time = SQ.time\n",
    "AND GDOT.time = PYPL.time \"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "etf_portfolio = pd.read_sql_query(query, con = engine)\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "etf_portfolio.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.007038\n",
       "1   -0.001216\n",
       "2    0.008567\n",
       "3   -0.001004\n",
       "4   -0.008243\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame that displays the mean value of the “daily_returns” columns for all four assets.\n",
    "etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis = 1)\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "etf_portfolio_returns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use the average daily returns in the etf_portfolio_returns DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4382727240061359"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the annualized return for the portfolio. \n",
    "annualized_etf_portfolio_returns = etf_portfolio_returns.mean()*252\n",
    "\n",
    "# Display the annualized return value of the ETF portfolio.\n",
    "annualized_etf_portfolio_returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etf_portfolio_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_48047/2825689499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use the average daily returns provided by the etf_portfolio_returns DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# to calculate the cumulative returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0metf_cumulative_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0metf_portfolio_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Display the final cumulative return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'etf_portfolio_returns' is not defined"
     ]
    }
   ],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the cumulative returns\n",
    "etf_cumulative_returns = (1+ etf_portfolio_returns).cumprod()\n",
    "\n",
    "# Display the final cumulative return value\n",
    "etf_cumulative_returns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etf_cumulative_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/vdjh_fg101ngh4h3c4ywfly80000gn/T/ipykernel_48047/3820232225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using hvplot, create an interactive line plot that visualizes the ETF portfolios cumulative return values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m etf_cumulative_returns.hvplot(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ETF - FinTech Stocks (GDOT, GS, PYPL, SQ): Growth of $1 USD Initial Investment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cumulative Investment [$]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'etf_cumulative_returns' is not defined"
     ]
    }
   ],
   "source": [
    "# Using hvplot, create an interactive line plot that visualizes the ETF portfolios cumulative return values.\n",
    "etf_cumulative_returns.hvplot(\n",
    "    title=\"ETF - FinTech Stocks (GDOT, GS, PYPL, SQ): Growth of $1 USD Initial Investment\"\n",
    "    , ylabel=\"Cumulative Investment [$]\"\n",
    "    , xlabel= \"Date\"\n",
    "    , width=900\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7474887d3bec8742e9b57ca56e8642af7ad5814400d3eeec772b12c87c5ec38e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
